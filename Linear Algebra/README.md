# ğŸ“ Linear Algebra for Machine Learning  
### Visual Foundations with Manim â€” Sam SciTech

Linear Algebra is the **core mathematical language of Machine Learning**.  
This folder contains **carefully designed Manim animations** that visually
explain linear algebra concepts *exactly as they are used in ML models* â€”
from vectors and matrices to transformations and high-dimensional intuition.

These animations are created for **Sam SciTech** with the goal of helping
learners **see what machine learning is actually doing under the hood**.

---

## ğŸ¯ Why Linear Algebra Matters in Machine Learning

Every major ML and Deep Learning concept relies on linear algebra:

- Data is represented as **vectors**
- Datasets are **matrices**
- Model parameters are **weight vectors**
- Neural networks perform **linear transformations**
- Training is driven by **matrix multiplications**

If you understand linear algebra *visually*, ML becomes **simpler, clearer,
and far less abstract**.

---

## ğŸ§  Learning Philosophy

This repository focuses on:

- âœ… **Geometric intuition first**
- âœ… **Visual correctness (not just aesthetics)**
- âœ… **ML-aligned explanations**
- âœ… **Clean, reusable Manim scenes**
- âŒ No rote memorization
- âŒ No symbol overload without meaning

Every animation answers one question:

> *â€œWhat is the machine actually doing?â€*

---

## ğŸ“‚ Folder Structure

```text
Linear_Algebra/
â”œâ”€â”€ Vector_Visualizations/
â”‚   â”œâ”€â”€ vector_vs_line.py
â”‚   â”œâ”€â”€ vector_components.py
â”‚
â”œâ”€â”€ Matrix_Operations/
â”‚   â”œâ”€â”€ matrix_multiplication.py
â”‚   â”œâ”€â”€ linear_transformation.py
â”‚
â”œâ”€â”€ Eigen_Concepts/
â”‚   â”œâ”€â”€ eigenvectors_visual.py
â”‚   â”œâ”€â”€ eigenvalues_intuition.py
â”‚
â””â”€â”€ README.md
```
Each .py file contains a self-contained Manim scene that corresponds
to a specific concept used in Machine Learning

---
## ğŸ§© Topics Covered (ML-Focused)

### ğŸ”¹ Vectors
- Feature vectors and data representation
- Direction vs magnitude in feature space
- Column vectors in ML datasets
- Why a vector is **not** a straight line
- Vector intuition behind dot products

### ğŸ”¹ Matrices
- Data matrices and batch representation
- Weight matrices in ML models
- Matrix multiplication as feature transformation
- Understanding linear layers geometrically

### ğŸ”¹ Linear Transformations
- Scaling, rotation, projection, and shear
- Transforming feature spaces
- How neural network layers reshape data
- Geometric meaning of affine transformations

### ğŸ”¹ Eigenvalues & Eigenvectors
- Principal directions in data
- Dominant features and stability
- Visual intuition behind PCA
- Dimensionality reduction concepts

---

## ğŸ¤– Machine Learning Connections

Each visualization in this folder directly maps to machine learning concepts such as:

- Linear Regression
- Logistic Regression
- Gradient Descent (geometric intuition)
- Neural Network layers
- Principal Component Analysis (PCA)
- High-dimensional feature spaces

The goal is to **bridge mathematical intuition and ML implementation**.

---

## â–¶ï¸ Running the Animations

### Requirements
- Python 3.10+
- Manim Community Edition
- NumPy

### Example Command

```bash
manim -pqh filename.py classname
